{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델 1: snunlp/KR-ELECTRA-discriminator 테스트 데이터 예측 시작 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 35/35 [00:09<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델 2: beomi/KcELECTRA-base-v2022 테스트 데이터 예측 시작 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 35/35 [00:09<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델 3: monologg/koelectra-base-v3-discriminator 테스트 데이터 예측 시작 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 35/35 [00:02<00:00, 12.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# test.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# STSDataset 클래스는 앞서 수정한 내용을 사용합니다.\n",
    "class STSDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence1 = str(self.df.loc[idx, 'sentence_1'])\n",
    "        sentence2 = str(self.df.loc[idx, 'sentence_2'])\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sentence1,\n",
    "            sentence2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].squeeze()  # [max_len]\n",
    "        attention_mask = inputs['attention_mask'].squeeze()  # [max_len]\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': input_ids.to(device),\n",
    "            'attention_mask': attention_mask.to(device),\n",
    "        }\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = self.df.loc[idx, 'label']\n",
    "            item['labels'] = torch.tensor(label, dtype=torch.float).to(device)\n",
    "        \n",
    "        return item\n",
    "# 모델 클래스 정의 (이전과 동일)\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc1 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.regressor = nn.Linear(self.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        \n",
    "        x = self.dropout(pooled_output)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        outputs = self.regressor(x)\n",
    "        return outputs.squeeze()\n",
    "\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv('/data/ephemeral/home/data/test.csv')  # 테스트 데이터 파일 경로를 입력하세요\n",
    "\n",
    "# 토크나이저와 데이터셋 생성\n",
    "max_len = 128\n",
    "batch_size = 32\n",
    "\n",
    "model_names = [\n",
    "    'snunlp/KR-ELECTRA-discriminator',\n",
    "    'beomi/KcELECTRA-base-v2022',\n",
    "    'monologg/koelectra-base-v3-discriminator',\n",
    "]\n",
    "\n",
    "tokenizers = []\n",
    "test_loaders = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizers.append(tokenizer)\n",
    "    \n",
    "    test_dataset = STSDataset(test_df, tokenizer, max_len, is_train=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "test_predictions = []\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(f\"\\n=== 모델 {i+1}: {model_name} 테스트 데이터 예측 시작 ===\")\n",
    "    # 모델 생성 및 체크포인트 로드\n",
    "    model = RegressionModel(model_name).to(device)\n",
    "\n",
    "    # checkpoint = torch.load(f'/data/ephemeral/home/yujin/results/model_{i+1}.pt')\n",
    "    # # 체크포인트에서 현재 모델과 크기가 일치하는 파라미터만 필터링\n",
    "    # filtered_state_dict = {k: v for k, v in checkpoint.items() if k in model.state_dict() and model.state_dict()[k].shape == v.shape}\n",
    "    # # 모델에 로드\n",
    "    # model.load_state_dict(filtered_state_dict, strict=False)\n",
    "    # try:\n",
    "    #     # State_dict에서 불일치하는 파라미터를 건너뛰고 로드\n",
    "    #     model.load_state_dict(filtered_state_dict, strict=False)\n",
    "    # except RuntimeError as e:\n",
    "    #     print(f\"RuntimeError occurred: {e}\")\n",
    "    #     print(\"Continuing with the rest of the code...\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'/data/ephemeral/home/yujin/results/new_model_{i+1}.pt'), strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loader = test_loaders[i]\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Testing'):\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask']\n",
    "            )\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    test_predictions.append(preds)\n",
    "\n",
    "# 앙상블 예측 (테스트 데이터)\n",
    "ensemble_test_preds = np.mean(test_predictions, axis=0)\n",
    "# 예측 값을 필요한 범위로 클리핑 (예: 0~5 사이)\n",
    "ensemble_test_preds = np.clip(ensemble_test_preds, 0.0, 5.0)\n",
    "\n",
    "ensemble_test_preds = np.round(ensemble_test_preds,1)\n",
    "\n",
    "# 결과 저장\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': ensemble_test_preds\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "output_df.to_csv('/data/ephemeral/home/yujin/results/output_02.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
